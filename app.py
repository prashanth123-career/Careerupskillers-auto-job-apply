import streamlit as st
import pandas as pd
from datetime import datetime
import os

# âœ… Set page config FIRST
st.set_page_config(page_title="All-in-One Job Auto-Applier", page_icon="ğŸ’¼")

# âœ… Title and description
st.title("ğŸ’¼ All-in-One Job Auto-Applier")
st.markdown("Apply smartly with AI-powered cover letters and resume autofill.")

# âœ… Import modules
try:
    from utils.scrapers import scrape_internshala, scrape_indeed, scrape_naukri, scrape_timesjobs
    from utils.cover_letter import generate_cover_letter
    from utils.resume_parser import parse_resume
except Exception as e:
    st.error(f"Error importing modules: {e}")

# âœ… Upload Resume
st.subheader("ğŸ“„ Upload Your Resume")
resume_file = st.file_uploader("Upload your resume (PDF or DOCX)", type=["pdf", "docx"])
resume_text = ""
if resume_file:
    resume_text = parse_resume(resume_file)
    st.success("Resume uploaded and parsed successfully!")

# âœ… Platform selection
st.subheader("ğŸŒ Select Platforms")
platforms = st.multiselect(
    "Choose platforms to search:",
    ["Internshala", "Naukri", "Indeed", "TimesJobs", "LinkedIn"],
    default=["Internshala"]
)

# âœ… Search filters
st.subheader("ğŸ” Search Filters")
keyword = st.text_input("Job Title / Keywords", value="Data Science")
location = st.text_input("Location", value="Remote")
use_gpt = st.checkbox("Generate AI-based Cover Letter", value=True)
mode = st.radio("Application Mode", ["Manual Click", "Auto Apply (where possible)"])

# âœ… Search Jobs Button
if st.button("Search Jobs") and keyword and platforms:
    st.info("Searching jobs on selected platforms...")
    results = []

    for platform in platforms:
        try:
            if platform == "Internshala":
                scraped = scrape_internshala(keyword)
                results += scraped
                st.write(f"âœ… Internshala found: {len(scraped)} jobs")
            elif platform == "Naukri":
                scraped = scrape_naukri(keyword, location)
                results += scraped
                st.write(f"âœ… Naukri found: {len(scraped)} jobs")
            elif platform == "Indeed":
                scraped = scrape_indeed(keyword, location)
                results += scraped
                st.write(f"âœ… Indeed found: {len(scraped)} jobs")
            elif platform == "TimesJobs":
                scraped = scrape_timesjobs(keyword, location)
                results += scraped
                st.write(f"âœ… TimesJobs found: {len(scraped)} jobs")
            elif platform == "LinkedIn":
                st.warning("LinkedIn supports only manual click mode. Showing jobs only.")
        except Exception as e:
            st.error(f"âŒ Error scraping {platform}: {e}")

    # âœ… Fallback job if scrapers fail
    if len(results) == 0:
        st.warning("âš ï¸ No jobs found from platforms. Showing a test job below.")
        results.append({
            "Title": "AI Intern - Sales & Marketing",
            "Company": "CareerUpskillers",
            "Platform": "Demo",
            "Link": "https://careerupskillers.com"
        })

    # âœ… Show results
    if results:
        st.success(f"Found {len(results)} jobs.")
        log = []
        for job in results:
            st.markdown("---")
            st.markdown(f"### ğŸ¢ {job['Title']} at {job['Company']}")
            st.markdown(f"ğŸŒ Platform: {job['Platform']}")
            st.markdown(f"ğŸ”— [View Job]({job['Link']})")

            if use_gpt and resume_text:
                with st.expander("ğŸ§  View AI-Generated Cover Letter"):
                    try:
                        st.write(generate_cover_letter(resume_text, job['Title']))
                    except Exception as e:
                        st.error(f"âš ï¸ GPT Error: {e}")

            if mode == "Auto Apply (where possible)":
                st.button(f"ğŸš€ Auto Apply (Coming Soon)", key=job['Link'])
            else:
                st.markdown(f"[ğŸ–±ï¸ Click to Apply]({job['Link']})")

            log.append({
                "Title": job['Title'],
                "Company": job['Company'],
                "Platform": job['Platform'],
                "Link": job['Link'],
                "Time": datetime.now()
            })

        df = pd.DataFrame(log)
        df.to_csv("applied_jobs_log.csv", index=False)
        st.success("Log saved as applied_jobs_log.csv")

    else:
        st.warning("No jobs found. Try different filters.")
